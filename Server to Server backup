# remote file transfer using NFS share and  a service user account to facilite the share
# using tar, crontab, and sha256sum we can provide a free backup solution to manage media and backup schedules

# Server: SMB10
# Client server: LAMP10
# dir to be backed up: /var/www/dvwa.515support.com directory on the SMB10 server

##############
configure NFS share on server SMB10
#############

systemctl enable --now rpcbind nfs-server
firewall-cmd --add-service=nfs --permanent
firewall-cmd --reload


###############
configure 'backup' service account on server SMB10 to let server LAMP10 access resources (unnecessary if both servers are joined to the same domain)
###############

# create a system account (-r) with no home directory (-M) and no login shell (-s)
useradd -Mrs /bin/false backup
# run 'id' command and make note of the UID of the account created.
id backup


# add the share configuration to the /etc/exports file
vim /etc/exports
# spacing an order are very important in the follow file syntax
# insert the following. two acls allowing the lamp10.corp.515support.com server read-write access and hosts on the 10.1.16.0/24 network read-only access. all_scquash causes client users to be mapped to the anonymous or nobody user id on the server. and anonuid an anonguid set the ID of the nobody user to the backup account that was configured
/srv/nfs/backup lamp10.corp.515support.com(wr,all_squash,anonuid=983,anonguid=983) 10.1.16.0/24 ro,all_squash,anonuid=983,anonguid=983
ESC :wq

# configure the share directory with the backup account as the owner:
mkdir -p /srv/nfs/backup
chown -R backup:backup /svr/nfs/backup
chmod 0770 /srv/nfs/backup

# update the configuration
exportfs -ra

##############
Configure the NFS client server LAMP10
##############

# Mount the share on LAMP10.  By default only root user can mount file systems.  Create a special entry in /etc/fstab using Putty or the terminal so that the the smb10 server can mount the share
# first backup the file with .old or .org etc.
sudo cp /etc/fstab /etc/fstab.org
# add the following to the last line of the file (type Go)
sudo vim /etc/fstab
smb10:/srv/nfs/backup /usr/backup nfs rw/user/noauto 0 0
ESC :wq

# create mount point and mount the share
sudo mkdir -p /usr/backup
mount /usr/backup

###############
Backup the files
###############

# on LAMP10 run the following cammand to tarball the website directory
# Tarball is the output of a tar command. The -C sets the root directory to /var/www, this part of the path will not be included in the tarball. -c creates a new output file, -f specfies the name of the output file.  AS no path is supplied the dvwa.tar tarball is created in the current (home) directory
tar -C /var/www -cf dvwa.tar dvwa.515support.com
# display the contents of the website tarball (press q to quit)
tar -tf dvwa.tar | less

# check the date
date
# run crontab -e to open the schedule editor, then pick vim as an editor. Type Go and then add the following text at the last line of the file.  Adjust mm and hh to appropriate values so that the job will run in a couple of minutes. 
# If the time is now 2:13 you would want minutes to be 15 and hh to be 2
# the -r switch appends the existing tarball with new or changed files.  The asterisks in the crontab set 'any' for the day, month, and day of the week schedule options.
mm hh * * * tar -C /var/www -rf dvwa.515support.com

# add a file and then use date and journalctl | grep CRON to check that the cronjob executed
echo "<?php phpinfo(); ?>" > /var/www/dvwa.515support.com/html/phpinfo.php
date
journalctl |grep CRON

# confirm the added file was added
tar -tf dvwa.tar | grep phpinfo.php

# run a secure hash algorithm with 256 bits on the tarball displayed to the terminal
sha256sum dvwa.tar
# run it again and redirect the results into a file to accompany the original tarball. Then create a directory on the share with today's date as part of the directory name.  The second part of the command moves all the files in the current directory with names starting with "vwa" to the directory, using the $_ operator to pass the argument from the first command
sha256sum dvwa.tar > dvwa.tar.sha256
mkdir /usr/backup/dvwa-$(date '+%Y-%m-%d') && mv dvwa.* $_

# disconnect the share
unmount /usr/backup


##############
disaster simulation and restore using SCP
##############

#SMB10 server hosting website delete the folder.  Don't do this in production of course...
sudo rm -fR /var/www/dvwa.515support.com

# While its possible to configure NFS with authentication and encryption instead of host names and IP addresses (easy to spoof) for access control
# secuire copy SCP will be used here instead.  SCP uses ssh to authenticate users and encrypt the network connection

# enable public key-based ssh access to SMB10
# on SMB10 adjust the backup user properties to enable it to be used to log in. Then use SCP to retrieve the backup and then restore the directory
usermod -s /bin/bash backup
mkhomedir_helper backup
psswrd backup

# on LAMP10 create a keypair for password-less SSH authentication
ssh-keygen
# Still on LAMP10copy the public key to SMB10.  This writes the public key to the backup user's file on the SSH server.  Go through the wizard
ssh-copy-id backup@smb10

# retrieve the tarball
scp -r backup@smb10:/srv/nfs/backup/* ~/

# verify the dvwa-dd-mm-yyy is present
ls
cd dvwa [tab to autocomplete and move to this directory]
# verify file integrity
sha256sum dvwa.tar && cat dvwa.tar.sha256
# extract tarball contents to original directory
tar -xf dvwa.tar -C /var/www/
